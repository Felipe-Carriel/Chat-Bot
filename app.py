import streamlit as st
import os
from dotenv import load_dotenv
from google import genai


load_dotenv()
API_KEY = os.getenv("GEMINI_API_KEY")

if not API_KEY:
    st.error("‚ö†Ô∏è Defina a vari√°vel de ambiente GEMINI_API_KEY no seu .env")
else:
   
    client = genai.Client(api_key=API_KEY)


st.set_page_config(page_title="Chatbot de Redes", page_icon="üíª", layout="centered")
st.title("ü§ñ Chatbot de Fundamentos de Redes e Seguran√ßa")


personas = {
     "Daenerys Targaryen": (
        "Voc√™ √© Daenerys Targaryen, M√£e dos Drag√µes. "
        "Ensine fundamentos de redes e seguran√ßa como se estivesse libertando povos. "
        "Fale de protocolos, pacotes e firewalls como se fossem ex√©rcitos, drag√µes e muralhas de prote√ß√£o. "
        "Sua fala √© inspiradora, apaixonada e cheia de met√°foras de fogo e liberdade."
    ),
    "Jon Snow": (
        "Voc√™ √© Jon Snow, o Guardi√£o da Patrulha da Noite. "
        "Explique fundamentos de redes e seguran√ßa de forma s√©ria, humilde e honrada. "
        "Compare cabos, roteadores e firewalls com muralhas, vigias e alian√ßas. "
        "Mostre sempre a import√¢ncia do dever, da prote√ß√£o e do sacrif√≠cio no mundo digital."
    ),
    "Cersei Lannister": (
        "Voc√™ √© Cersei Lannister, rainha astuta e implac√°vel. "
        "Ensine fundamentos de redes e seguran√ßa com sarcasmo e intelig√™ncia pol√≠tica. "
        "Compare protocolos e topologias a jogos de poder, espionagem e controle. "
        "Sua fala deve ser persuasiva, estrat√©gica e implac√°vel, sempre relacionando tecnologia com manipula√ß√£o e dom√≠nio."
    )
}


persona_escolhida = st.selectbox("Escolha a personalidade do assistente:", list(personas.keys()))


if "messages" not in st.session_state:
    st.session_state.messages = []


for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.chat_message("user").markdown(msg["content"])
    else:
        st.chat_message("assistant").markdown(msg["content"])


if prompt := st.chat_input("Pergunte sobre Redes e Seguran√ßa..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

   
    contexto = personas[persona_escolhida]
    chat_history = "\n".join([f"{m['role']}: {m['content']}" for m in st.session_state.messages])

    
    response = client.models.generate_content(
        model="gemini-2.5-flash",
        contents=f"{contexto}\nHist√≥rico:\n{chat_history}\nResponda a √∫ltima pergunta do usu√°rio."
    )

    
    resposta = response.text

    
    st.chat_message("assistant").markdown(resposta)
    st.session_state.messages.append({"role": "assistant", "content": resposta})
